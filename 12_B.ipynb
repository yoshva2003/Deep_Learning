{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "qs = [\"hi\", \"how are you\", \"what is your name\", \"bye\"]\n",
        "ans = [\"hello\", \"i am fine\", \"i am a chatbot\", \"goodbye\"]\n",
        "ans_in = [\"<start> \" + a for a in ans]\n",
        "ans_out = [a + \" <end>\" for a in ans]\n",
        "\n",
        "tok = Tokenizer(filters='')\n",
        "tok.fit_on_texts(qs + ans_in + ans_out)\n",
        "vocab = len(tok.word_index) + 1\n",
        "maxlen = max(len(s.split()) for s in qs + ans_in + ans_out)\n",
        "enc_in = pad_sequences(tok.texts_to_sequences(qs), maxlen=maxlen)\n",
        "dec_in = pad_sequences(tok.texts_to_sequences(ans_in), maxlen=maxlen)\n",
        "dec_out = pad_sequences(tok.texts_to_sequences(ans_out), maxlen=maxlen)\n",
        "\n",
        "ei, di = Input((maxlen,)), Input((maxlen,))\n",
        "emb = Embedding(vocab, 64)\n",
        "ee = emb(ei)\n",
        "de = emb(di)\n",
        "_, h, c = LSTM(128, return_state=True)(ee)\n",
        "dl, _, _ = LSTM(128, return_sequences=True, return_state=True)(de, initial_state=[h, c])\n",
        "out = Dense(vocab, activation='softmax')(dl)\n",
        "model = Model([ei, di], out)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit([enc_in, dec_in], np.expand_dims(dec_out, -1), epochs=300, verbose=0)\n",
        "\n",
        "def chat(msg):\n",
        "    seq = pad_sequences(tok.texts_to_sequences([msg]), maxlen=maxlen)\n",
        "    dec = np.zeros((1, maxlen)); dec[0, 0] = tok.word_index['<start>']\n",
        "    for i in range(1, maxlen):\n",
        "        p = model.predict([seq, dec], verbose=0)\n",
        "        w = np.argmax(p[0, i-1])\n",
        "        dec[0, i] = w\n",
        "        if w == tok.word_index.get('<end>'): break\n",
        "    txt = tok.sequences_to_texts(dec)[0]\n",
        "    return txt.replace('<start>', '').replace('<end>', '').strip()\n",
        "\n",
        "print(\"User: how are you\")\n",
        "print(\"Bot :\", chat(\"how are you\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goWXeqM2W2N1",
        "outputId": "23d3e1d8-4910-442c-a5f4-f21ea2ffc5d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: how are you\n",
            "Bot : i am fine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIUSFx0vepsV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}